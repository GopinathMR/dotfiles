
# General Settings
#logging=true
generate=1
temperature=1.0
type="conventional"

# Model-Specific Settings

[OLLAMA]
host=http://localhost:11434
model[]=deepseek-r1:latest
numCtx=4096
